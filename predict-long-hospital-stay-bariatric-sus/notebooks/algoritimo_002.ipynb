{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5caeca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, roc_auc_score, roc_curve,\n",
    "    mean_squared_error, r2_score, mean_absolute_error\n",
    ")\n",
    "import xgboost as xgb\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Ambiente configurado!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e559047",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"bariatrica_sp_mg_2018_2023.xlsx\")\n",
    "print(f\"Dados carregados: {len(df)} registros\")\n",
    "\n",
    "# Verificar estat√≠sticas de interna√ß√£o\n",
    "print(\"\\nEstat√≠sticas de DIAS_PERM:\")\n",
    "print(df['DIAS_PERM'].describe())\n",
    "\n",
    "media_dias = df['DIAS_PERM'].mean()\n",
    "mediana_dias = df['DIAS_PERM'].median()\n",
    "\n",
    "print(f\"\\n M√©dia de dias: {media_dias:.2f}\")\n",
    "print(f\" Mediana de dias: {mediana_dias:.0f}\")\n",
    "\n",
    "# Testar dois limiares para classifica√ß√£o\n",
    "limiar_3_dias = 3\n",
    "limiar_media = media_dias\n",
    "\n",
    "df['LONGA_3_DIAS'] = (df['DIAS_PERM'] > limiar_3_dias).astype(int)\n",
    "df['LONGA_MEDIA'] = (df['DIAS_PERM'] > limiar_media).astype(int)\n",
    "\n",
    "print(f\"\\n Casos >3 dias: {df['LONGA_3_DIAS'].sum()} ({df['LONGA_3_DIAS'].mean()*100:.1f}%)\")\n",
    "print(f\" Casos >m√©dia ({media_dias:.1f} dias): {df['LONGA_MEDIA'].sum()} ({df['LONGA_MEDIA'].mean()*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161965fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# 2. Preparar Dados para Modelagem \n",
    "# =============================================\n",
    "\n",
    "# Lista de CIDs de comorbidades relevantes para complica√ß√µes p√≥s-bari√°trica\n",
    "COMORBIDADES_CID = {\n",
    "    'DIABETES': ['E10', 'E11', 'E13', 'E14'],\n",
    "    'HIPERTENSAO': ['I10', 'I11', 'I12', 'I13', 'I15'],\n",
    "    'DOENCA_CARDIACA': ['I20', 'I21', 'I22', 'I23', 'I24', 'I25', 'I30', 'I31', 'I33', 'I34', 'I35', 'I37', 'I38', 'I39', 'I40', 'I41', 'I42', 'I43', 'I44', 'I45', 'I46', 'I47', 'I48', 'I49', 'I50'],\n",
    "    'DOENCA_PULMONAR': ['J40', 'J41', 'J42', 'J43', 'J44', 'J45', 'J46', 'J47'],\n",
    "    'DOENCA_RENAL': ['N18', 'N19', 'I12', 'I13'],\n",
    "    'TROMBOEMBOLISMO': ['I26', 'I80', 'I81', 'I82'],\n",
    "    'APNEIA_SONO': ['G473'],\n",
    "    'OBESIDADE_GRAVES': ['E660', 'E661', 'E662', 'E668', 'E669'],\n",
    "    'DISLIPIDEMIA': ['E78'],\n",
    "    'ACIDO_PEPTICO': ['K25', 'K26', 'K27', 'K28'],\n",
    "    'DOENCA_HEPATICA': ['K70', 'K71', 'K72', 'K73', 'K74', 'K75', 'K76'],\n",
    "    'DEPRESSAO': ['F32', 'F33', 'F34'],\n",
    "    'ANSIEDADE': ['F41'],\n",
    "    'OSTEOPOROSE': ['M80', 'M81', 'M82'],\n",
    "    'ARTROSE': ['M15', 'M16', 'M17', 'M18', 'M19'],\n",
    "}\n",
    "\n",
    "def extrair_grupo_cid(codigo_cid):\n",
    "    \"\"\"Extrai os primeiros 3 caracteres do CID (ex: E110 ‚Üí E11)\"\"\"\n",
    "    if pd.isna(codigo_cid) or not isinstance(codigo_cid, str):\n",
    "        return \"DESCONHECIDO\"\n",
    "    return codigo_cid[:3] if len(codigo_cid) >= 3 else \"DESCONHECIDO\"\n",
    "\n",
    "def criar_flags_comorbidades(df):\n",
    "    \"\"\"Cria flags bin√°rias para comorbidades baseadas em DIAG_PRINC e DIAGSEC1-9\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Criar coluna de grupo CID para diagn√≥stico principal\n",
    "    df['CID_PRINC_GRUPO'] = df['DIAG_PRINC'].apply(extrair_grupo_cid)\n",
    "    \n",
    "    # Criar colunas para diagn√≥sticos secund√°rios (concatenar todos)\n",
    "    diag_sec_cols = [col for col in df.columns if col.startswith('DIAGSEC') and not col.startswith('TPDISEC')]\n",
    "    df['DIAG_SECUNDARIOS'] = df[diag_sec_cols].fillna('').apply(\n",
    "        lambda row: '|'.join([extrair_grupo_cid(x) for x in row if pd.notna(x) and x != '']), axis=1\n",
    "    )\n",
    "    \n",
    "    # Criar flags para cada comorbidade\n",
    "    for nome_comorbidade, cids in COMORBIDADES_CID.items():\n",
    "        flag_col = f\"PREOP_{nome_comorbidade}\"\n",
    "        # Verifica se o CID principal ou algum secund√°rio est√° na lista\n",
    "        df[flag_col] = df.apply(\n",
    "            lambda row: int(\n",
    "                row['CID_PRINC_GRUPO'] in cids or \n",
    "                any(cid in cids for cid in row['DIAG_SECUNDARIOS'].split('|') if cid != '')\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Aplicar fun√ß√£o de comorbidades\n",
    "df = criar_flags_comorbidades(df)\n",
    "\n",
    "# Tratar RACA_COR: 99 = ignorado / n√£o informado ‚Üí converter para NaN\n",
    "if 'RACA_COR' in df.columns:\n",
    "    df['RACA_COR'] = df['RACA_COR'].replace(99, np.nan)\n",
    "\n",
    "# Selecionar features PR√â-OPERAT√ìRIAS (dispon√≠veis antes da cirurgia) \n",
    "features_candidatas = [\n",
    "    # Demogr√°ficas\n",
    "    'IDADE',            # Idade do paciente \n",
    "    'SEXO',             # Sexo (1=M, 3=F)\n",
    "    'RACA_COR',         # Ra√ßa/cor\n",
    "    \n",
    "    # Cl√≠nicas (pr√©-existentes)\n",
    "    'DIAG_PRINC',       # Diagn√≥stico principal (obesidade)\n",
    "    'CID_PRINC_GRUPO',  # Grupo do CID principal\n",
    "    \n",
    "    # Flags de comorbidades (calculadas acima)\n",
    "    'PREOP_DIABETES',\n",
    "    'PREOP_HIPERTENSAO',\n",
    "    'PREOP_DOENCA_CARDIACA',\n",
    "    'PREOP_DOENCA_PULMONAR',\n",
    "    'PREOP_DOENCA_RENAL',\n",
    "    'PREOP_TROMBOEMBOLISMO',\n",
    "    'PREOP_APNEIA_SONO',\n",
    "    'PREOP_OBESIDADE_GRAVES',\n",
    "    'PREOP_DISLIPIDEMIA',\n",
    "    'PREOP_ACIDO_PEPTICO',\n",
    "    'PREOP_DOENCA_HEPATICA',\n",
    "    'PREOP_DEPRESSAO',\n",
    "    'PREOP_ANSIEDADE',\n",
    "    'PREOP_OSTEOPOROSE',\n",
    "    'PREOP_ARTROSE',\n",
    "    \n",
    "    # Institucionais\n",
    "    'COMPLEX',          # x, nos dados do SIH/SUS todos estao iguas, foi deixado pois nao afeta o modelo e facilita a reultiliza√ß√£o\n",
    "    'FINANC',           # x, nos dados do SIH/SUS todos estao iguas, foi deixado pois nao afeta o modelo e facilita a reultiliza√ß√£o\n",
    "    \n",
    "    # Socioecon√¥micas\n",
    "    'INSTRU',           # x, nos dados do SIH/SUS todos estao iguas, foi deixado pois nao afeta o modelo e facilita a reultiliza√ß√£o\n",
    "    'NUM_FILHOS',       # x, nos dados do SIH/SUS todos estao iguas, foi deixado pois nao afeta o modelo e facilita a reultiliza√ß√£o\n",
    "    \n",
    "    # Estado (apenas para estratifica√ß√£o na divis√£o, N√ÉO como feature)\n",
    "    'ESTADO_ORIGEM'     # MG ou SP\n",
    "    #IMC por√©m n√£o h√° dados\n",
    "]\n",
    "\n",
    "# Filtrar colunas existentes\n",
    "features = [col for col in features_candidatas if col in df.columns]\n",
    "X = df[features].copy()\n",
    "y_reg = df['DIAS_PERM'].copy()  # Alvo para regress√£o\n",
    "\n",
    "# Definir alvo de classifica√ß√£o: interna√ß√£o longa (>3 dias)\n",
    "y_clf = (df['DIAS_PERM'] > 3).astype(int)\n",
    "\n",
    "print(f\"Features selecionadas (pr√©-operat√≥rias, sem vari√°veis temporais): {len(features)}\")\n",
    "print(\"Lista de features:\")\n",
    "for f in features:\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "# Remover 'ESTADO_ORIGEM' de X (n√£o deve ser usado como feature preditiva)\n",
    "if 'ESTADO_ORIGEM' in X.columns:\n",
    "    X = X.drop(columns=['ESTADO_ORIGEM'])\n",
    "\n",
    "\n",
    "# Tratar valores ausentes\n",
    "for col in X.columns:\n",
    "    if col == 'RACA_COR':\n",
    "        # Imputar moda (valor mais frequente entre 1, 3, etc.)\n",
    "        moda = X[col].mode()\n",
    "        if len(moda) > 0:\n",
    "            X[col] = X[col].fillna(moda[0])\n",
    "        else:\n",
    "            X[col] = X[col].fillna(3)  # valor padr√£o (Parda, mais comum no Brasil)\n",
    "    elif X[col].dtype == 'object':\n",
    "        X[col] = X[col].fillna('DESCONHECIDO')\n",
    "    else:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "# Codificar vari√°veis categ√≥ricas\n",
    "label_encoders = {}\n",
    "for col in X.select_dtypes(include='object').columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(f\"\\nDados preparados: {X.shape[0]} registros, {X.shape[1]} features\")\n",
    "\n",
    "# Dividir dados (estratificado por estado ‚Äî apenas para garantir representatividade, n√£o como feature)\n",
    "X_train, X_test, y_train_clf, y_test_clf = train_test_split(\n",
    "    X, y_clf, test_size=0.2, random_state=42, stratify=df['ESTADO_ORIGEM']\n",
    ")\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, y_reg, test_size=0.2, random_state=42, stratify=df['ESTADO_ORIGEM']\n",
    ")\n",
    "\n",
    "print(f\"Divis√£o conclu√≠da: {len(X_train)} treino, {len(X_test)} teste\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dcf865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3. Treinar Modelos de Classifica√ß√£o (Comparar Limiares)\n",
    "\n",
    "def treinar_modelos_classificacao(y_target, nome_alvo):\n",
    "    print(f\"\\nüîç Treinando modelos para alvo: {nome_alvo}\")\n",
    "    \n",
    "    y_train = y_train_reg.copy() if y_target is y_reg else y_target.loc[y_train_reg.index]\n",
    "    y_test = y_target.loc[y_test_reg.index]\n",
    "    \n",
    "    # XGBoost\n",
    "    model_xgb = xgb.XGBClassifier(n_estimators=300, max_depth=6, random_state=42)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    y_pred_xgb = model_xgb.predict(X_test)\n",
    "    y_proba_xgb = model_xgb.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Random Forest\n",
    "    model_rf = RandomForestClassifier(n_estimators=300, max_depth=10, random_state=42)\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    y_pred_rf = model_rf.predict(X_test)\n",
    "    y_proba_rf = model_rf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Rede Neural\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    model_nn = MLPClassifier(hidden_layer_sizes=(64,32), max_iter=1000, random_state=42)\n",
    "    model_nn.fit(X_train_scaled, y_train)\n",
    "    y_pred_nn = model_nn.predict(X_test_scaled)\n",
    "    y_proba_nn = model_nn.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # M√©tricas\n",
    "    def get_metrics(y_true, y_pred, y_proba):\n",
    "        auc = roc_auc_score(y_true, y_proba)\n",
    "        report = classification_report(y_true, y_pred, output_dict=True)\n",
    "        f1 = report['weighted avg']['f1-score']\n",
    "        return auc, f1\n",
    "    \n",
    "    metrics = {}\n",
    "    metrics['XGBoost'] = get_metrics(y_test, y_pred_xgb, y_proba_xgb)\n",
    "    metrics['Random Forest'] = get_metrics(y_test, y_pred_rf, y_proba_rf)\n",
    "    metrics['Rede Neural'] = get_metrics(y_test, y_pred_nn, y_proba_nn)\n",
    "    \n",
    "    # Melhor modelo\n",
    "    melhor_modelo = max(metrics.keys(), key=lambda k: metrics[k][0])  # maior AUC\n",
    "    melhor_auc = metrics[melhor_modelo][0]\n",
    "    \n",
    "    print(f\"Melhor AUC: {melhor_auc:.3f} ({melhor_modelo})\")\n",
    "    \n",
    "    return {\n",
    "        'metrics': metrics,\n",
    "        'melhor_modelo': melhor_modelo,\n",
    "        'melhor_auc': melhor_auc,\n",
    "        'y_test': y_test,\n",
    "        'y_pred_xgb': y_pred_xgb,\n",
    "        'y_proba_xgb': y_proba_xgb,\n",
    "        'y_pred_rf': y_pred_rf,\n",
    "        'y_proba_rf': y_proba_rf,\n",
    "        'y_pred_nn': y_pred_nn,\n",
    "        'y_proba_nn': y_proba_nn,\n",
    "        'model_xgb': model_xgb,\n",
    "        'model_rf': model_rf,\n",
    "        'model_nn': model_nn\n",
    "    }\n",
    "\n",
    "# Treinar para ambos os limiares\n",
    "result_3_dias = treinar_modelos_classificacao(df['LONGA_3_DIAS'], \"LONGA_3_DIAS\")\n",
    "result_media = treinar_modelos_classificacao(df['LONGA_MEDIA'], \"LONGA_MEDIA\")\n",
    "\n",
    "# Escolher melhor limiar\n",
    "if result_3_dias['melhor_auc'] > result_media['melhor_auc']:\n",
    "    print(f\"\\n Melhor limiar: >3 dias (AUC={result_3_dias['melhor_auc']:.3f})\")\n",
    "    class_result = result_3_dias\n",
    "    alvo_classificacao = 'LONGA_3_DIAS'\n",
    "    limiar_escolhido = limiar_3_dias\n",
    "else:\n",
    "    print(f\"\\n Melhor limiar: >m√©dia ({media_dias:.1f} dias, AUC={result_media['melhor_auc']:.3f})\")\n",
    "    class_result = result_media\n",
    "    alvo_classificacao = 'LONGA_MEDIA'\n",
    "    limiar_escolhido = media_dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e90176",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_3_dias = treinar_modelos_classificacao(df['LONGA_3_DIAS'], \"LONGA_3_DIAS\")\n",
    "result_media = treinar_modelos_classificacao(df['LONGA_MEDIA'], \"LONGA_MEDIA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54403819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolher melhor limiar e salvar o modelo treinado\n",
    "if result_3_dias['melhor_auc'] > result_media['melhor_auc']:\n",
    "    print(f\"\\n Melhor limiar: >3 dias (AUC={result_3_dias['melhor_auc']:.3f})\")\n",
    "    class_result = result_3_dias\n",
    "    alvo_classificacao = 'LONGA_3_DIAS'\n",
    "    limiar_escolhido = limiar_3_dias\n",
    "else:\n",
    "    print(f\"\\n Melhor limiar: >m√©dia ({media_dias:.1f} dias, AUC={result_media['melhor_auc']:.3f})\")\n",
    "    class_result = result_media\n",
    "    alvo_classificacao = 'LONGA_MEDIA'\n",
    "    limiar_escolhido = media_dias\n",
    "\n",
    "# ‚úÖ SALVAR O MODELO TREINADO GLOBALMENTE\n",
    "model_rf = class_result['model_rf']  # Agora 'model_rf' existe no escopo global!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f1fe76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 4. Treinar Modelos de Regress√£o\n",
    "\n",
    "print(\"\\n Treinando modelos de regress√£o...\")\n",
    "\n",
    "# XGBoost Regressor\n",
    "model_xgb_reg = xgb.XGBRegressor(n_estimators=150, max_depth=6, random_state=42)\n",
    "model_xgb_reg.fit(X_train, y_train_reg)\n",
    "y_pred_xgb_reg = model_xgb_reg.predict(X_test)\n",
    "\n",
    "# Random Forest Regressor\n",
    "model_rf_reg = RandomForestRegressor(n_estimators=150, max_depth=10, random_state=42)\n",
    "model_rf_reg.fit(X_train, y_train_reg)\n",
    "y_pred_rf_reg = model_rf_reg.predict(X_test)\n",
    "\n",
    "# Rede Neural Regressor\n",
    "scaler_reg = StandardScaler()\n",
    "X_train_scaled_reg = scaler_reg.fit_transform(X_train)\n",
    "X_test_scaled_reg = scaler_reg.transform(X_test)\n",
    "\n",
    "model_nn_reg = MLPRegressor(hidden_layer_sizes=(64,32), max_iter=500, random_state=42)\n",
    "model_nn_reg.fit(X_train_scaled_reg, y_train_reg)\n",
    "y_pred_nn_reg = model_nn_reg.predict(X_test_scaled_reg)\n",
    "\n",
    "# M√©tricas de regress√£o\n",
    "def get_reg_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return rmse, mae, r2\n",
    "\n",
    "metrics_reg = {}\n",
    "metrics_reg['XGBoost'] = get_reg_metrics(y_test_reg, y_pred_xgb_reg)\n",
    "metrics_reg['Random Forest'] = get_reg_metrics(y_test_reg, y_pred_rf_reg)\n",
    "metrics_reg['Rede Neural'] = get_reg_metrics(y_test_reg, y_pred_nn_reg)\n",
    "\n",
    "print(\"\\n DESEMPENHO DOS MODELOS DE REGRESS√ÉO:\")\n",
    "for model_name, (rmse, mae, r2) in metrics_reg.items():\n",
    "    print(f\"{model_name:15s} | RMSE: {rmse:.2f} | MAE: {mae:.2f} | R¬≤: {r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399e5a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97719373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 5. Gerar 5 Figuras Otimizadas para Revista\n",
    "\n",
    "print(\"\\n Gerando figuras...\")\n",
    "\n",
    "# Figura 1: Desempenho de Classifica√ß√£o + Compara√ß√£o de Limiares\n",
    "fig1, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "# fig1.suptitle('Figura 1: Desempenho de Classifica√ß√£o', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Compara√ß√£o de AUC entre limiares\n",
    "axes[0,0].bar(['>3 dias', f'>m√©dia ({media_dias:.1f} dias)'], \n",
    "              [result_3_dias['melhor_auc'], result_media['melhor_auc']], \n",
    "              color=['#FF6B6B', '#4ECDC4'])\n",
    "axes[0,0].set_title(\"Compara√ß√£o de Limiares (Melhor AUC)\")\n",
    "axes[0,0].set_ylabel(\"AUC\")\n",
    "for i, v in enumerate([result_3_dias['melhor_auc'], result_media['melhor_auc']]):\n",
    "    axes[0,0].text(i, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom')\n",
    "\n",
    "# Matriz de Confus√£o (melhor modelo)\n",
    "cm = confusion_matrix(class_result['y_test'], class_result['y_pred_xgb'])\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0,1])\n",
    "axes[0,1].set_title(f\"Matriz Confus√£o - {class_result['melhor_modelo']}\")\n",
    "\n",
    "# F1-Score dos modelos (limiar escolhido)\n",
    "models = list(class_result['metrics'].keys())\n",
    "f1s = [class_result['metrics'][m][1] for m in models]\n",
    "axes[1,0].bar(models, f1s, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "axes[1,0].set_title(f\"F1-Score - Limiar: {limiar_escolhido:.1f} dias\")\n",
    "axes[1,0].set_ylabel(\"F1\")\n",
    "for i, v in enumerate(f1s):\n",
    "    axes[1,0].text(i, v + 0.01, f\"{v:.3f}\", ha='center', va='bottom')\n",
    "\n",
    "# Distribui√ß√£o de probabilidades\n",
    "axes[1,1].hist(class_result['y_proba_xgb'], bins=20, alpha=0.7, color='#FF6B6B')\n",
    "axes[1,1].axvline(0.5, color='red', linestyle='--', label='Limiar 0.5')\n",
    "axes[1,1].set_title(\"Distribui√ß√£o de Probabilidades - XGBoost\")\n",
    "axes[1,1].set_xlabel(\"Probabilidade\")\n",
    "axes[1,1].set_ylabel(\"Frequ√™ncia\")\n",
    "axes[1,1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig1_classificacao.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c14051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figura 2: Curvas ROC + Import√¢ncia de Features\n",
    "fig2, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "# fig2.suptitle('Figura 2: Curvas ROC e Import√¢ncia de Features', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Curvas ROC\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(class_result['y_test'], class_result['y_proba_xgb'])\n",
    "fpr_rf, tpr_rf, _ = roc_curve(class_result['y_test'], class_result['y_proba_rf'])\n",
    "fpr_nn, tpr_nn, _ = roc_curve(class_result['y_test'], class_result['y_proba_nn'])\n",
    "\n",
    "axes[0].plot(fpr_xgb, tpr_xgb, label=f'XGBoost (AUC={class_result[\"metrics\"][\"XGBoost\"][0]:.3f})', linewidth=2)\n",
    "axes[0].plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC={class_result[\"metrics\"][\"Random Forest\"][0]:.3f})', linewidth=2)\n",
    "axes[0].plot(fpr_nn, tpr_nn, label=f'Rede Neural (AUC={class_result[\"metrics\"][\"Rede Neural\"][0]:.3f})', linewidth=2)\n",
    "axes[0].plot([0,1], [0,1], 'k--', alpha=0.5)\n",
    "axes[0].set_xlabel('FPR')\n",
    "axes[0].set_ylabel('TPR')\n",
    "axes[0].set_title('Curvas ROC')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Import√¢ncia de Features\n",
    "if hasattr(class_result['model_xgb'], 'feature_importances_'):\n",
    "    feat_imp = pd.Series(class_result['model_xgb'].feature_importances_, index=X.columns).nlargest(10)\n",
    "    feat_imp.plot(kind='barh', ax=axes[1], color='#4ECDC4')\n",
    "    axes[1].set_title('Top 10 Features')\n",
    "    axes[1].set_xlabel('Import√¢ncia')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"fig2_roc_features.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b45ea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figura 3: Desempenho de Regress√£o\n",
    "fig3, axes = plt.subplots(1, 3, figsize=(16, 6))\n",
    "# fig3.suptitle('Figura 3: Desempenho de Regress√£o', fontsize=14, fontweight='bold')\n",
    "\n",
    "# RMSE\n",
    "models_reg = list(metrics_reg.keys())\n",
    "rmses = [metrics_reg[m][0] for m in models_reg]\n",
    "axes[0].bar(models_reg, rmses, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "axes[0].set_title(\"RMSE\")\n",
    "axes[0].set_ylabel(\"RMSE\")\n",
    "for i, v in enumerate(rmses):\n",
    "    axes[0].text(i, v + 0.05, f\"{v:.2f}\", ha='center', va='bottom')\n",
    "\n",
    "# R¬≤\n",
    "r2s = [metrics_reg[m][2] for m in models_reg]\n",
    "axes[1].bar(models_reg, r2s, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "axes[1].set_title(\"R¬≤\")\n",
    "axes[1].set_ylabel(\"R¬≤\")\n",
    "for i, v in enumerate(r2s):\n",
    "    axes[1].text(i, v + 0.005, f\"{v:.3f}\", ha='center', va='bottom')\n",
    "\n",
    "# Scatter Plot (melhor modelo de regress√£o)\n",
    "melhor_modelo_reg = max(metrics_reg.keys(), key=lambda k: metrics_reg[k][2])  # maior R¬≤\n",
    "if melhor_modelo_reg == 'XGBoost':\n",
    "    y_pred_best = y_pred_xgb_reg\n",
    "elif melhor_modelo_reg == 'Random Forest':\n",
    "    y_pred_best = y_pred_rf_reg\n",
    "else:\n",
    "    y_pred_best = y_pred_nn_reg\n",
    "\n",
    "axes[2].scatter(y_test_reg, y_pred_best, alpha=0.6, color='#4ECDC4')\n",
    "axes[2].plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)\n",
    "axes[2].set_xlabel(\"Valor Real\")\n",
    "axes[2].set_ylabel(\"Valor Previsto\")\n",
    "axes[2].set_title(f\"Scatter Plot - {melhor_modelo_reg}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig3_regressao.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figura 4: An√°lise Descritiva\n",
    "fig4, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "# fig4.suptitle('Figura 4: An√°lise Descritiva dos Dados', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Distribui√ß√£o de dias de interna√ß√£o\n",
    "axes[0,0].hist(df['DIAS_PERM'], bins=30, color='#4ECDC4', edgecolor='black')\n",
    "axes[0,0].axvline(limiar_escolhido, color='red', linestyle='--', label=f'Limiar escolhido ({limiar_escolhido:.1f})')\n",
    "axes[0,0].set_title(\"Distribui√ß√£o de Dias de Interna√ß√£o\")\n",
    "axes[0,0].set_xlabel(\"Dias\")\n",
    "axes[0,0].set_ylabel(\"Frequ√™ncia\")\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Propor√ß√£o de interna√ß√£o longa (limiar escolhido)\n",
    "df[alvo_classificacao].value_counts().plot.pie(\n",
    "    ax=axes[0,1], autopct='%1.1f%%', colors=['#4ECDC4', '#FF6B6B']\n",
    ")\n",
    "axes[0,1].set_title(f\"Propor√ß√£o de Interna√ß√£o Longa\\n(>{limiar_escolhido:.1f} dias)\")\n",
    "axes[0,1].set_ylabel(\"\")\n",
    "\n",
    "# Taxa por estado\n",
    "taxa_estado = df.groupby('ESTADO_ORIGEM')[alvo_classificacao].mean()\n",
    "taxa_estado.plot(kind='bar', ax=axes[1,0], color='#45B7D1')\n",
    "axes[1,0].set_title(\"Taxa de Interna√ß√£o Longa por Estado\")\n",
    "axes[1,0].set_xlabel(\"Estado\")\n",
    "axes[1,0].set_ylabel(\"Taxa\")\n",
    "\n",
    "# Taxa por ano\n",
    "taxa_ano = df.groupby('ANO_CMPT')[alvo_classificacao].mean()\n",
    "taxa_ano.plot(kind='bar', ax=axes[1,1], color='#FF6B6B')\n",
    "axes[1,1].set_title(\"Taxa de Interna√ß√£o Longa por Ano\")\n",
    "axes[1,1].set_xlabel(\"Ano\")\n",
    "axes[1,1].set_ylabel(\"Taxa\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"fig4_descritiva.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d5004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc9d237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interna√ß√µes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
